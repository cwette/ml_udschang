{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df19eef",
   "metadata": {},
   "source": [
    "# **<center>TP 3 - Réseau de neurones artificiel</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c477151",
   "metadata": {},
   "source": [
    "## **<center>Exercice 1 - Prédiction du prix des maisons</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9fa0d",
   "metadata": {},
   "source": [
    "Il s'agit d'un problème de régression dont l'objectif est de modéliser le prix des maisons en milliers de dollars. \n",
    "\n",
    "La base de données de maisons comprend 9 attributs numériques, dont 8 attributs d'entrée et 1 attribut cible qui est le prix des maisons a predire.\n",
    "\n",
    "La performance du modèle sera évaluée à l'aide de l'erreur quadratique moyenne (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97d0f3-bc5a-4a58-9ae0-a8b194276f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ea9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les librairies necessaires\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3c70c",
   "metadata": {},
   "source": [
    "### **Acquisition des données**\n",
    "\n",
    "Nous allons importer les donnees de la libraire sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af734323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california_housing = fetch_california_housing()\n",
    "# Afficher la description des attributs\n",
    "print(california_housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ae1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les données en dataframe\n",
    "california = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "california['PRICE'] = california_housing.target\n",
    "california.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bd81b",
   "metadata": {},
   "source": [
    "### **Analyse des données**\n",
    "\n",
    "Nous voulons voir s'il y a une correlation entre la variable cible et d'autres variables.\n",
    "Nous allons faire un seul graphique, mais vous pouvez en faire d'autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ed4a8-6ad3-4050-8a75-0a505aaea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "california.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63712c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completez le code suivant pour affichez la distribution des prix des maisons sur un graphique\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.distplot(..., bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b893b9",
   "metadata": {},
   "source": [
    "### **Transformation des donnees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completer le code pour separer l'ensemble des variables independantes (X) et la variable dependante (Y) \n",
    "X = california_housing...\n",
    "Y = california_housing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separer les sous-ensembles d'entrainement (X_train, Y_train) et les sous-ensembles de test (X_test, Y_test) \n",
    "from sklearn.model_selection import train_test_split\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03341b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les sous-ensembles d'entrainement\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04561c-f52b-4705-a236-8d99eb49e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(california_housing.data,\n",
    "                                                    california_housing.target, random_state=11)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa58e53",
   "metadata": {},
   "source": [
    "### **Construction du modele**\n",
    "\n",
    "Ci-dessous, nous allons définir plusieurs fonctions pour créer le modèle de base en variant les hyperparametres comme le nombre de couches, le nombre de neurones, le nombre d'iteration, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7966f",
   "metadata": {},
   "source": [
    "Le premier est un modèle simple qui a une seule couche cachée entièrement connectée avec le même nombre de neurones que les attributs d'entrée (13). Ce réseau utilise de bonnes pratiques telles que la fonction d'activation du 'relu' pour la couche cachée.\n",
    "Aucune fonction d'activation n'est utilisée pour la couche de sortie qui a un seul neurone car il s'agit d'un problème de régression et nous nous intéressons à prédire les valeurs numériques directement sans transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un modele de base 2 couches dont une couche cachée de 8 neurones et une couche de sortie\n",
    "# La couche des variables d'entrée a 8 noeuds, input_dim=8\n",
    "def baseline_model():\n",
    "    # creer le modele\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compiler le modele\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele pour 100 iterations\n",
    "regressor = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "regressor.fit(X_train,Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1ed27-dbb8-4631-89c1-2c537a4b1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faire des predictions\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer la performance avec la fonction mean_squared_error\n",
    "mse_krr = mean_squared_error(Y_test, y_pred)\n",
    "print(mse_krr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiser les resultats dans un diargam\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(Y_test, label=\"y-original\")\n",
    "plt.plot(y_pred, label=\"y-predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9712a",
   "metadata": {},
   "source": [
    "Definir un second modele de base plus large a 2 couches dont une couche cachée de 25 neurones et une couche de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edf8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementer la methode suivante pour creer un reseau de neurones plus large avec 2 couches dont\n",
    "# une couche cachée de 25 neurones et une couche de sortie d'un seul neurone\n",
    "def model_large():\n",
    "    # creer le modele\n",
    "    ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf74638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele a nouveau pour 100 iterations\n",
    "...\n",
    "\n",
    "#Faire des predictions\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fba985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer la performance avec la fonction mean_squared_error\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc96ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiser les resultats dans un diargam de taille (25,10)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2390d",
   "metadata": {},
   "source": [
    "Definir un troisieme modele de base plus profond qui 4 couches dont 3 couches cachées de 8, 8 et 4 neurones respectivement et une couche de sortie. Les couches cachée utilise la fonction d'activation 'relu' tandis que la couche de sortie utilise la fonction d'activation 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementer la methode suivante pour creer un reseau de neurones plus profond avec 4 couches dont\n",
    "# 3 couches cachées de 8, 8 et 4 neurones respectivement et une couche de sortie. \n",
    "# Les couches cachée utilise la fonction d'activation 'relu' tandis que la couche de sortie utilise \n",
    "# la fonction d'activation 'linear'\n",
    "def model_profond():\n",
    "    # creer le modele\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478066db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele a nouveau\n",
    "...\n",
    "\n",
    "#Faire des predictions\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer la performance avec la fonction mean_squared_error\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiser les resultats dans un diargam de taille (25,10)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e34ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c58d644",
   "metadata": {},
   "source": [
    "## **<center>Exercice 2 - Classification d'images</center>**\n",
    "\n",
    "L'ensemble de données CIFAR-10 comprend 60 000 photos réparties en 10 classes (d'où le nom CIFAR-10). Les classes incluent des objets tels que des avions, des automobiles, des oiseaux, des chats, etc. L'ensemble de données est divisé de manière standard, où 50 000 images sont utilisées pour entraîner un modèle et les 10 000 autres pour évaluer ses performances.\n",
    "\n",
    "Les photos sont en couleur avec des composantes rouges, vertes et bleues, mais de petite taille mesurant des carrés de 32 x 32 pixels.\n",
    "\n",
    "Il existe un concours Kaggle qui utilise les données CIFAR-10. C'est un bon endroit pour rejoindre la discussion sur le développement de nouveaux modèles pour le problème et choisir des modèles et des scripts comme point de départ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338dbeff",
   "metadata": {},
   "source": [
    "### **Acquisition des données**\n",
    "\n",
    "L'ensemble de données CIFAR-10 peut facilement être importé de la librairie Keras à l'aide de la fonction cifar10.load_data() pour les stocker dans le répertoire <repertoire courant>/.keras/datasets . Cet ensemble de données est volumineux à 163 mégaoctets, son téléchargement peut donc prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "# lire les données\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6b7bf",
   "metadata": {},
   "source": [
    "### **Analyse des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez un sous-emsemble des données\n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b945739",
   "metadata": {},
   "source": [
    "### **Normalisation des données**\n",
    "\n",
    "Les valeurs de pixel des images sont comprises entre 0 et 255 pour chacun des canaux rouge, vert et bleu.\n",
    "\n",
    "Parce que les valeurs d'entrée sont bien comprises, nous pouvons facilement normaliser la plage de 0 à 1 en divisant chaque valeur par l'observation maximale qui est de 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisez inputs X_train et X_test from 0-255 to 0.0-1.0\n",
    "# Completer le code\n",
    "X_train = ... / 255.0\n",
    "X_test = ... / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393d386",
   "metadata": {},
   "source": [
    "### **Variables cibles**\n",
    "\n",
    "Les variables de sortie sont définies comme un vecteur d'entiers de 0 à 1 pour chaque classe. \n",
    "\n",
    "Nous pouvons utiliser un \"one hot encoding\" pour les transformer en une matrice binaire afin de modéliser au mieux le problème de classification. Nous savons qu'il existe 10 classes pour ce problème, et la matrice binaire aaura donc une largeur de 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d83481",
   "metadata": {},
   "source": [
    "### **Réseau de neurones à convolution (CNN)**\n",
    "\n",
    "Pour résoudre CIFAR-10, nous pouvons commencer par importer toutes les classes et fonctions dont nous aurons besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2394dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding de la variable de sortie\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4db41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66574857",
   "metadata": {},
   "source": [
    "Construction du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45446283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Completer le code pour creer le modele\n",
    "cifar10_model=tf.keras.models.Sequential()\n",
    "\n",
    "# Ajoutez une 1ere couche d'entrée convolutive, 32 filtres avec une taille de 3×3, une fonction d'activation 'relu', \n",
    "# taille du kernel = 3, image de taille (32,32,3)\n",
    "cifar10_model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding=\"same\", activation=\"relu\", input_shape=[32,32,3]))\n",
    "\n",
    "# Ajoutez une 2e couche convolutive, 32 filtres, taille du kernel = 3, une fonction d'activation 'relu' \n",
    "...\n",
    "\n",
    "# Ajoutez une 3e couche Max Pooling de taille pool_size=2\n",
    "cifar10_model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2,padding='valid'))\n",
    "...\n",
    "\n",
    "# Ajoutez une 4e couche convolutive, 64 filtres, taille du kernel = 3, une fonction d'activation 'relu'\n",
    "...\n",
    "\n",
    "# Ajoutez une 5e couche convolutive, 64 filtres, taille du kernel = 3, une fonction d'activation 'relu'\n",
    "...\n",
    "\n",
    "# Ajoutez une 6e couche Max Pooling de taille pool_size=2\n",
    "...\n",
    "\n",
    "# Ajoutez une couche d'applatissement (Flattening Layer)\n",
    "cifar10_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Ajoutez une couche Droput pour supprimer un pourcentage de neurones \n",
    "cifar10_model.add(tf.keras.layers.Dropout(0.5,noise_shape=None,seed=None))\n",
    "\n",
    "# Ajoutez une couche entièrement connectée Dense() avec 12u unités et la fonction d'activation 'relu'\n",
    "...\n",
    "\n",
    "# Ajoutez la couche de sortie. Sachant que c'est un modele multi-classes de 10 classes, \n",
    "# vous devez completez ici le nombre d'unites et le type de fonction d'activation, 'sigmoid' ou 'softmax'\n",
    "cifar10_model.add(tf.keras.layers.Dense(units=...,activation='...'))\n",
    "\n",
    "# Affichez une description du modele\n",
    "cifar10_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c91bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modele\n",
    "cifar10_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "# Entrainez le modele pour 15 iterations\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer la performance du modele\n",
    "test_loss, test_accuracy = cifar10_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd40f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
